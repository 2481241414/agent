import pandas as pd
import os
import json
import ast
import numpy as np
import math
from tqdm import tqdm
from collections import defaultdict
import time
import itertools
from sklearn.model_selection import train_test_split

# --- å¬å›å™¨å’Œè¯„æµ‹æ¨¡å— (è¯„æµ‹æ¨¡å—ä¸å˜, å¬å›å™¨å·²ä¿®æ”¹) ---
from rank_bm25 import BM25Okapi
import jieba
from sklearn.metrics import roc_auc_score


# ã€ä¿®æ”¹ç‚¹ã€‘ToolRetriever ç±»è¢«é‡æ„ä»¥é€‚åº”æ–°çš„é€»è¾‘
class ToolRetriever:
    """
    æ–°çš„å¬å›å™¨é€»è¾‘ï¼š
    1. BM25 åœ¨ä¸€ä¸ªç”±æ‰€æœ‰â€œæŒ‡ä»¤â€ç»„æˆçš„è¯­æ–™åº“ä¸Šæ„å»ºç´¢å¼•ã€‚
    2. å½“æŸ¥è¯¢æ—¶ï¼Œé¦–å…ˆå¬å›æœ€ç›¸å…³çš„â€œæŒ‡ä»¤â€ã€‚
    3. ç„¶åï¼Œå°†è¿™äº›æŒ‡ä»¤çš„åˆ†æ•°èšåˆåˆ°å®ƒä»¬å„è‡ªå¯¹åº”çš„â€œå·¥å…·â€ä¸Šã€‚
    4. æœ€ç»ˆè¿”å›å¾—åˆ†æœ€é«˜çš„ã€å»é‡åçš„å·¥å…·åˆ—è¡¨ã€‚
    """
    def __init__(self, instruction_corpus: list, instruction_to_tool_map: list, all_tools_definitions: list, k1=1.5, b=0.75):
        self.instruction_corpus = instruction_corpus
        self.instruction_to_tool_map = instruction_to_tool_map # è®°å½•æ¯æ¡æŒ‡ä»¤å¯¹åº”çš„å·¥å…·
        self.all_tools_definitions = all_tools_definitions
        self.k1 = k1
        self.b = b
        
        # ä¸ºäº†æ–¹ä¾¿èšåˆåˆ†æ•°ï¼Œé¢„å…ˆæ„å»ºå·¥å…·ååˆ°å®šä¹‰å’Œç´¢å¼•çš„æ˜ å°„
        self.tool_name_to_def = {tool['name']: tool for tool in self.all_tools_definitions}
        self.tool_name_to_index = {tool['name']: i for i, tool in enumerate(self.all_tools_definitions)}
        
        # é¢„å…ˆè®¡ç®—æ¯ä¸ªå·¥å…·å¯¹åº”å“ªäº›æŒ‡ä»¤çš„ç´¢å¼•ï¼Œç”¨äºåŠ é€Ÿåˆ†æ•°èšåˆ
        self.tool_to_instruction_indices = defaultdict(list)
        for i, tool_list in enumerate(self.instruction_to_tool_map):
            if tool_list:
                # å‡è®¾æ¯æ¡æŒ‡ä»¤åªå¯¹åº”ä¸€ä¸ªçœŸå®å·¥å…·
                tool_name = tool_list[0]['name']
                self.tool_to_instruction_indices[tool_name].append(i)

        self._add_jieba_words()
        
        # åœ¨æŒ‡ä»¤è¯­æ–™åº“ä¸Šæ„å»º BM25 æ¨¡å‹
        tokenized_corpus = [self._tokenize(doc) for doc in self.instruction_corpus]
        self.bm25 = BM25Okapi(tokenized_corpus, k1=self.k1, b=self.b)

    def _tokenize(self, text: str) -> list[str]:
        return jieba.lcut(text, cut_all=False)

    def _add_jieba_words(self):
        # jieba åŠ è½½è¯å…¸çš„é€»è¾‘ä¿æŒä¸å˜
        for tool in self.all_tools_definitions:
            jieba.add_word(tool.get('name', ''), freq=100)
        core_words = ["è´­ç‰©è½¦", "é‡‡è´­è½¦", "å¾…æ”¶è´§", "å¾…ä»˜æ¬¾", "æ”¶è—å¤¹", "é™ä»·", "ç­¾åˆ°", "ç§¯åˆ†", "å‘ç¥¨", "å¼€ç¥¨", "æŠ¥é”€å‡­è¯"]
        for word in core_words:
            jieba.add_word(word, freq=100)

    def retrieve_with_scores(self, query: str, top_k: int):
        tokenized_query = self._tokenize(query)
        
        # 1. è®¡ç®—æŸ¥è¯¢ä¸è¯­æ–™åº“ä¸­æ¯æ¡â€œæŒ‡ä»¤â€çš„ç›¸ä¼¼åº¦åˆ†æ•°
        instruction_scores = self.bm25.get_scores(tokenized_query)
        
        # 2. èšåˆåˆ†æ•°ï¼šå°†æŒ‡ä»¤çš„åˆ†æ•°èµ‹ç»™å…¶å¯¹åº”çš„å·¥å…·
        #    - ä¸€ä¸ªå·¥å…·çš„åˆ†æ•°ï¼Œæ˜¯æ‰€æœ‰æŒ‡å‘å®ƒçš„æŒ‡ä»¤åˆ†æ•°ä¸­çš„æœ€å¤§å€¼ã€‚
        #    - è¿™æ˜¯ä¸ºäº†è§£å†³ AUC è¯„æµ‹éœ€è¦æ¯ä¸ªå·¥å…·éƒ½æœ‰ä¸€ä¸ªåˆ†æ•°çš„é—®é¢˜ã€‚
        num_total_tools = len(self.all_tools_definitions)
        aggregated_tool_scores = np.zeros(num_total_tools)
        
        for tool_name, instruction_indices in self.tool_to_instruction_indices.items():
            if not instruction_indices:
                continue
            # è·å–è¯¥å·¥å…·å¯¹åº”çš„æ‰€æœ‰æŒ‡ä»¤çš„åˆ†æ•°ï¼Œå¹¶å–æœ€å¤§å€¼
            max_score = np.max(instruction_scores[instruction_indices])
            tool_idx = self.tool_name_to_index[tool_name]
            aggregated_tool_scores[tool_idx] = max_score

        # 3. æ ¹æ®èšåˆåçš„å·¥å…·åˆ†æ•°è¿›è¡Œæ’åºå’Œç­›é€‰
        #    - `argsort` è¿”å›çš„æ˜¯ä»å°åˆ°å¤§çš„ç´¢å¼•ï¼Œæ‰€ä»¥éœ€è¦å€’åº
        top_k_tool_indices = np.argsort(aggregated_tool_scores)[-top_k:][::-1]
        
        # è¿‡æ»¤æ‰åˆ†æ•°ä¸º0çš„å·¥å…·
        retrieved_tools = [
            self.all_tools_definitions[i] 
            for i in top_k_tool_indices 
            if aggregated_tool_scores[i] > 0
        ]
        
        return retrieved_tools, aggregated_tool_scores


def _get_tool_names(tools: list) -> set:
    if not isinstance(tools, list): return set()
    return {tool.get('name') for tool in tools}

def calculate_recall_at_k(retrieved: list, ground_truth: list, k: int) -> float:
    if not ground_truth: return 1.0
    retrieved_names_at_k = _get_tool_names(retrieved[:k])
    ground_truth_names = _get_tool_names(ground_truth)
    if not ground_truth_names: return 1.0
    return len(retrieved_names_at_k.intersection(ground_truth_names)) / len(ground_truth_names)

def calculate_completeness_at_k(retrieved: list, ground_truth: list, k: int) -> float:
    if not ground_truth: return 1.0
    retrieved_names_at_k = _get_tool_names(retrieved[:k])
    ground_truth_names = _get_tool_names(ground_truth)
    return 1.0 if ground_truth_names.issubset(retrieved_names_at_k) else 0.0

def calculate_ndcg_at_k(retrieved: list, ground_truth: list, k: int) -> float:
    ground_truth_names = _get_tool_names(ground_truth)
    if not ground_truth_names: return 1.0
    dcg = sum(1.0 / math.log2(i + 2) for i, tool in enumerate(retrieved[:k]) if tool.get('name') in ground_truth_names)
    idcg = sum(1.0 / math.log2(i + 2) for i in range(min(len(ground_truth_names), k)))
    return dcg / idcg if idcg > 0 else 0.0

def calculate_hit_ratio_at_k(retrieved: list, ground_truth: list, k: int) -> float:
    retrieved_names = _get_tool_names(retrieved[:k])
    return 1.0 if retrieved_names & _get_tool_names(ground_truth) else 0.0

def calculate_average_precision_at_k(retrieved: list, ground_truth: list, k: int) -> float:
    gt_names = _get_tool_names(ground_truth)
    if not gt_names: return 1.0
    hit_count = 0
    sum_prec = 0.0
    for i, tool in enumerate(retrieved[:k]):
        if tool.get('name') in gt_names:
            hit_count += 1
            sum_prec += hit_count / (i + 1)
    return sum_prec / len(gt_names)

def calculate_mrr_at_k(retrieved: list, ground_truth: list, k: int) -> float:
    gt_names = _get_tool_names(ground_truth)
    for i, tool in enumerate(retrieved[:k]):
        if tool.get('name') in gt_names:
            return 1.0 / (i + 1)
    return 0.0

def calculate_auc_for_query(all_scores: np.ndarray, tool_defs: list, ground_truth: list) -> float:
    gt_names = _get_tool_names(ground_truth)
    labels = [1 if t['name'] in gt_names else 0 for t in tool_defs]
    try:
        if len(set(labels)) < 2: return 0.5
        return roc_auc_score(labels, all_scores)
    except ValueError: return 0.5


# --- å·¥å…·å®šä¹‰æ¨¡å— (ä¿æŒä¸å˜) ---
def get_exact_tool_definitions():
    tools = [
        # ... (å·¥å…·å®šä¹‰åˆ—è¡¨ä¿æŒä¸å˜ï¼Œæ­¤å¤„çœç•¥ä»¥èŠ‚çœç¯‡å¹…) ...
        # 1. è´­ç‰© - æœç´¢ (1.1)
        {"name": "search_goods(app, search_info_slot, page_type, filter_detail_slot, type_slot, area_slot, order_type)", "description": "åœ¨appç¨‹åºä¸­ä¾æ®åç§°æœç´¢å•†å“,å¯ä»¥æŒ‡å®šå…·ä½“åœ¨å“ªä¸€ä¸ªå­é¡µé¢è¿›è¡Œæœç´¢, æœç´¢ç»“æœçš„ç­›é€‰æ¡ä»¶å’Œæ’åºæ–¹å¼"},
        {"name": "search_stores(app, search_info_slot, filter_type, filter_detail_slot, location_slot, qualification_slot, order_type)", "description": "åœ¨appç¨‹åºä¸­ä¾æ®åç§°æœç´¢åº—é“º,å¯ä»¥ä½¿ç”¨ç­›é€‰å™¨é™åˆ¶æœç´¢ç»“æœ,ä¹Ÿå¯ä»¥æŒ‡å®šæœç´¢ç»“æœçš„æ’åºæ–¹å¼"},
        {"name": "open_search_history(app)", "description": "æ‰“å¼€appç¨‹åºçš„æœç´¢å†å²ç•Œé¢"},
        {"name": "delete_search_history(app)", "description": "æ¸…é™¤appä¸­çš„æœç´¢å†å²"},
        {"name": "open_camera_search(app)", "description": "æ‰“å¼€appç¨‹åºçš„å›¾ç‰‡æœç´¢åŠŸèƒ½"},
        {"name": "search_delivery_time(app, search_info_slot, address_slot)", "description": "æœç´¢ä¸€ä»¶å•†å“å¹¶æ ¹æ®ç»™å‡ºçš„åœ°å€æŸ¥è¯¢è¯¥å•†å“é€è¾¾è¯¥åœ°å€çš„é¢„ä¼°è¿é€æ—¶é—´"},
        {"name": "search_cart_content(app, search_info_slot)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­æŸ¥çœ‹è´­ç‰©è½¦/é‡‡è´­è½¦(é˜¿é‡Œå·´å·´çš„å«æ³•)æŸ¥æ‰¾å•†å“"},
        {"name": "search_in_favorite_goods(app, search_info_slot)", "description": "åœ¨appç¨‹åºä¸­æ‰“å¼€æ”¶è—çš„ã€å–œçˆ±ã€æƒ³è¦æˆ–å…³æ³¨å•†å“çš„é¡µé¢,å¹¶åœ¨å…¶ä¸­çš„æœç´¢æ ä¸­è¿›è¡Œæœç´¢"},
        {"name": "search_in_favorite_stores(app, search_info_slot)", "description": "åœ¨appç¨‹åºä¸­æ‰“å¼€æ”¶è—çš„å–œçˆ±æˆ–å…³æ³¨åº—é“ºçš„é¡µé¢,å¹¶åœ¨å…¶ä¸­çš„æœç´¢æ æœç´¢å•†å“"},
        {"name": "search_order(app, search_info_slot, order_status)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­æœç´¢è®¢å•"},

        # 2. è´­ç‰© - æ‰“å¼€ (1.2)
        {"name": "open_goods_page(app, search_info_slot, page_type)", "description": "é€šè¿‡å•†å“åç§°æ‰¾åˆ°å¹¶æ‰“å¼€å…¶è¯¦æƒ…é¡µé¢,å¯ä»¥æŒ‡å®šå­é¡µé¢,ä¾‹å¦‚è¯„è®ºã€è§„æ ¼ã€å‚æ•°ã€è¯¦æƒ…ç­‰"},
        {"name": "open_stores_page(app, store_name_slot, search_info_slot, category_slot)", "description": "é€šè¿‡åº—é“ºåç§°æ‰¾åˆ°å¹¶æ‰“å¼€åº—é“ºçš„å†…å®¹é¡µé¢,å¯ä»¥åœ¨å…¶ä¸­è¿›è¡Œåº—é“ºå†…æœç´¢æˆ–æ‰“å¼€ç±»åˆ«å­é¡µé¢"},
        {"name": "open_special_page(app, page_type)", "description": "æ‰“å¼€ç‰¹æ®Šé¡µé¢,ä¾‹å¦‚æ´»åŠ¨é¡µé¢"},

        # 3. è´­ç‰© - è´­ç‰©è½¦ (1.3)
        {"name": "open_cart_content(app, filter_type, filter_detail_slot)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­æŸ¥çœ‹è´­ç‰©è½¦/é‡‡è´­è½¦(é˜¿é‡Œå·´å·´çš„å«æ³•)æŒ‡å®šç±»å‹çš„å•†å“"},
        {"name": "add_into_cart(app, search_info_slot, specification_slot, num_slot, address_slot)", "description": "æœç´¢å•†å“å¹¶å°†å…¶æ·»åŠ å…¥è´­ç‰©è½¦,å¯ä»¥æŒ‡å®šæ·»åŠ çš„å•†å“è§„æ ¼ã€æ•°é‡å¹¶é€‰æ‹©æ”¶è´§åœ°å€"},

        # 4. è´­ç‰© - æ”¶è— (1.4)
        {"name": "open_favorite_goods(app, filter_type, filter_detail_slot, order_type)", "description": "åœ¨appç¨‹åºä¸­æ‰“å¼€æ”¶è—çš„å–œçˆ±ã€æƒ³è¦æˆ–å…³æ³¨å•†å“çš„é¡µé¢,å¹¶æŒ‰ç…§æ¡ä»¶è¿›è¡Œç­›é€‰"},
        {"name": "open_favorite_stores(app, filter_type)", "description": "åœ¨appç¨‹åºä¸­æ‰“å¼€æ”¶è—çš„å–œçˆ±æˆ–å…³æ³¨åº—é“ºçš„é¡µé¢,å¹¶æŒ‰ç…§æ¡ä»¶è¿›è¡Œç­›é€‰"},
        {"name": "add_into_favorite_goods(app, search_info_slot)", "description": "åœ¨appç¨‹åºä¸­æœç´¢å•†å“,å¹¶å°†å…¶æ·»åŠ åˆ°å•†å“æ”¶è—å¤¹ä¸­"},
        {"name": "add_into_favorite_stores(app, search_info_slot)", "description": "åœ¨appç¨‹åºä¸­æŒ‰ç…§åº—é“ºåæœç´¢åº—é“º,å¹¶å°†å…¶æ·»åŠ åˆ°åº—é“ºæ”¶è—å¤¹ä¸­"},
        {"name": "delete_favorite_goods(app, search_info_slot)", "description": "åœ¨appç¨‹åºçš„å•†å“æ”¶è—å¤¹ä¸­æœç´¢æŒ‡å®šå•†å“å¹¶å°†å…¶åˆ é™¤"},
        
        # 5. è´­ç‰© - ä¸‹å• (1.5)
        {"name": "order_to_purchase_goods(app, search_info_slot, specification_slot, num_slot, address_slot, payment_method_slot)", "description": "é€šè¿‡å•†å“åç§°æ‰¾åˆ°å•†å“å¹¶ä¸‹å•è´­ä¹°,å¯ä»¥æŒ‡å®šæ·»åŠ çš„å•†å“è§„æ ¼ã€æ•°é‡å¹¶é€‰æ‹©æ”¶è´§åœ°å€ä»¥åŠæ”¯ä»˜æ–¹å¼"},

        # 6. è´­ç‰© - è®¢å• (1.6)
        {"name": "open_orders_bought(app, order_status, filter_detail_slot)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­æŸ¥çœ‹ä¹°å…¥çš„æŒ‡å®šçŠ¶æ€çš„è®¢å•åˆ—è¡¨,ä¾‹å¦‚å¾…ä»˜æ¬¾ã€å¾…æ”¶è´§ã€å¾…è¯„ä»·ç­‰ã€‚"},
        {"name": "open_orders_sold(app, order_status, filter_detail_slot)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­æŸ¥çœ‹è‡ªå·±å”®å–çš„æŒ‡å®šçŠ¶æ€çš„è®¢å•åˆ—è¡¨,ä¾‹å¦‚å¾…ä»˜æ¬¾ã€å¾…æ”¶è´§ã€å¾…è¯„ä»·ç­‰ã€‚"},
        {"name": "open_orders_release(app, order_status)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­æŸ¥çœ‹è‡ªå·±å‘å¸ƒçš„æŒ‡å®šçŠ¶æ€çš„è®¢å•åˆ—è¡¨,ä¾‹å¦‚åœ¨å–ã€è‰ç¨¿ã€å·²ä¸‹æ¶ç­‰ã€‚"},
        {"name": "open_orders_all_review(app)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­æŸ¥çœ‹å¾…è¯„ä»·çŠ¶æ€çš„è®¢å•åˆ—è¡¨,åœ¨ä¸æŒ‡å®šè´­ä¹°è¿˜æ˜¯å”®å–çš„è®¢å•æ—¶,åŠå…¨éƒ½è¦çœ‹æ—¶ä½¿ç”¨ã€‚"},
        {"name": "apply_after_sales(app, search_info_slot, after_sales_type, reason_slot)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­æœç´¢è®¢å•,å¹¶ç”³è¯·å”®å"},

        # 7. è´­ç‰© - ç‰©æµ (1.7)
        {"name": "open_logistics_receive(app, filter_type)", "description": "æ‰“å¼€æ˜¾ç¤ºå·²è´­å•†å“ä¿¡æ¯çš„ç•Œé¢,æŸ¥çœ‹ç›¸å…³ç‰©æµä¿¡æ¯,å¹¶æ ¹æ®ç‰©æµæƒ…å†µè¿›è¡Œç­›é€‰"},
        {"name": "open_logistics_send(app, filter_type)", "description": "æ‰“å¼€æ˜¾ç¤ºå·²å”®å•†å“ä¿¡æ¯çš„ç•Œé¢,æŸ¥çœ‹ç›¸å…³ç‰©æµä¿¡æ¯,å¹¶æ ¹æ®ç‰©æµæƒ…å†µè¿›è¡Œç­›é€‰"},
        {"name": "open_express_delivery(app)", "description": "æ‰“å¼€appå¯„é€å¿«é€’çš„ç•Œé¢"},
        {"name": "manage_order_logistics_status(app, search_info_slot, action_type)", "description": "åœ¨appä¸­ç®¡ç†æŒ‡å®šè®¢å•çš„ç‰©æµçŠ¶æ€,åŒ…æ‹¬å‚¬å‘è´§,å‚¬é…é€,ç¡®è®¤æ”¶è´§"},
        {"name": "open_order_tracking_number(app, search_info_slot)", "description": "åœ¨appä¸­æŸ¥è¯¢æŒ‡å®šè®¢å•çš„ç‰©æµå•å·"},
        {"name": "call_order_courier(app, search_info_slot)", "description": "åœ¨appä¸­æ‹¨æ‰“æŒ‡å®šè®¢å•çš„å¿«é€’ç”µè¯"},

        # 8. è´­ç‰© - å®¢æœ (1.8)
        {"name": "open_customer_service(app, order_slot, store_slot)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­è”ç³»å®˜æ–¹å®¢æœ,æˆ–è”ç³»æŒ‡ä»¤è®¢å•çš„åº—é“ºå®¢æœ,æˆ–è”ç³»æŒ‡å®šåº—é“ºçš„å®¢æœ"},
        {"name": "apply_price_protection(app)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­è”ç³»å®¢æœè¿›è¡Œä»·ä¿"},

        # 9. è´­ç‰© - è¯„ä»· (1.9)
        {"name": "rate_order(app, search_info_slot, rating_slot, review_text_slot, upload_images)", "description": "åœ¨appåº”ç”¨ç¨‹åºè¯„ä»·å•†åŸä¸­çš„æŒ‡å®šè®¢å•"},

        # 10. è´­ç‰© - å‘ç¥¨ (1.10)
        {"name": "open_invoice_page(app, page_type)", "description": "åœ¨appåº”ç”¨ç¨‹åºä¸­æ‰“å¼€ä¸å‘ç¥¨ç›¸å…³çš„é¡µé¢"},

        # 11. è´­ç‰© - ç­¾åˆ° (1.11)
        {"name": "sign_in(app, page_type)", "description": "åœ¨appç¨‹åºä¸­å®Œæˆæ¯æ—¥ç­¾åˆ°,é¢†å–ç§¯åˆ†ã€é‡‘å¸ç­‰å¥–åŠ±çš„æ“ä½œ"},

        # 12. è´­ç‰© - å¯åŠ¨ (1.12)
        {"name": "open_app(app)", "description": "æ‰“å¼€æŒ‡å®šçš„åº”ç”¨ç¨‹åº"},
    ]
    return tools


# --- è¯­æ–™åº“æ„å»ºæ¨¡å— (å·²ä¿®æ”¹) ---
# ã€ä¿®æ”¹ç‚¹ã€‘é‡å†™è¯­æ–™åº“æ„å»ºå‡½æ•°
def build_instruction_corpus_and_mapping(data_df: pd.DataFrame):
    """
    ä¸ºæ•°æ®é›†ä¸­çš„æ¯ä¸€æ¡æŒ‡ä»¤åˆ›å»ºä¸€ä¸ªæ–‡æ¡£ã€‚
    è¿”å›:
        - instruction_corpus (list[str]): ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€æ¡ç”¨æˆ·æŒ‡ä»¤ã€‚
        - instruction_to_tool_map (list[list[dict]]): ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ç´¢å¼•ä¸ corpus å¯¹åº”ï¼Œ
          æ¯ä¸ªå…ƒç´ æ˜¯è¯¥æŒ‡ä»¤å¯¹åº”çš„ ground_truth_tool åˆ—è¡¨ã€‚
    """
    print("--- æ­£åœ¨æ„å»ºæŒ‡ä»¤è¯­æ–™åº“å’Œæ˜ å°„... ---")
    
    instruction_corpus = []
    instruction_to_tool_map = []

    for _, row in data_df.iterrows():
        # ä½¿ç”¨ 'æŒ‡ä»¤' åˆ—ä½œä¸ºæ–‡æ¡£å†…å®¹
        instruction_corpus.append(row['æŒ‡ä»¤']) 
        instruction_to_tool_map.append(row['ground_truth_tool'])

    print(f"æŒ‡ä»¤è¯­æ–™åº“æ„å»ºå®Œæˆï¼Œå…± {len(instruction_corpus)} æ¡æŒ‡ä»¤ã€‚\n")
    return instruction_corpus, instruction_to_tool_map


# --- ä¸»ç¨‹åº (å·²ä¿®æ”¹) ---
def main():
    # --- 0. é…ç½®åŒºåŸŸ ---
    annotated_data_file_path = r'D:\Agent\code\bm25_recall\data\single_gt_output_with_plan.csv' 
    K_VALUES = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    NUM_ERROR_EXAMPLES_TO_PRINT = 10 

    # --- 1. æ•°æ®åŠ è½½ ---
    print("--- æ­¥éª¤ 1: åŠ è½½å®Œæ•´æ•°æ®é›† ---")
    try:
        required_columns = ['query', 'æŒ‡ä»¤', 'planï¼ˆåœ¨xxä¸­åšä»€ä¹ˆï¼‰', 'ground_truth_tool']
        data_df = pd.read_csv(annotated_data_file_path, usecols=required_columns)
        data_df.dropna(subset=required_columns, inplace=True)
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–æ–‡ä»¶ '{annotated_data_file_path}' å¤±è´¥. {e}")
        return
    
    def parse_tools(tool_string):
        try: return ast.literal_eval(tool_string)
        except (ValueError, SyntaxError): return []
    data_df['ground_truth_tool'] = data_df['ground_truth_tool'].apply(parse_tools)
    # è¿‡æ»¤æ‰æ²¡æœ‰çœŸå®å·¥å…·æ ‡æ³¨çš„æ•°æ®
    data_df = data_df[data_df['ground_truth_tool'].apply(lambda x: isinstance(x, list) and len(x) > 0)]
    
    print(f"æ•°æ®åŠ è½½å®Œæˆ: å…± {len(data_df)} æ¡æœ‰æ•ˆæ ‡æ³¨æ•°æ®ã€‚æ‰€æœ‰æ•°æ®å°†ç”¨äºæ„å»ºå’Œè¯„æµ‹ã€‚\n")


    # --- 2. å‚æ•°æœç´¢ (Grid Search) ---
    print("--- æ­¥éª¤ 2: åœ¨å®Œæ•´æ•°æ®é›†ä¸Šæœç´¢æœ€ä½³ BM25 å‚æ•° ---")
    all_tools_definitions = get_exact_tool_definitions()
    
    # ã€ä¿®æ”¹ç‚¹ã€‘ä½¿ç”¨æ–°çš„å‡½æ•°æ„å»ºè¯­æ–™åº“å’Œæ˜ å°„
    instruction_corpus, instruction_to_tool_map = build_instruction_corpus_and_mapping(data_df)
    
    best_score = -1
    best_params = {'k1': 1.5, 'b': 0.75}
    k1_range = [1.2, 1.5, 1.8, 2.0]
    b_range = [0.6, 0.75, 0.9]

    for k1, b in tqdm(list(itertools.product(k1_range, b_range)), desc="å‚æ•°æœç´¢ä¸­"):
        # ã€ä¿®æ”¹ç‚¹ã€‘ä½¿ç”¨æ–°çš„å‚æ•°åˆå§‹åŒ–ä¸´æ—¶å¬å›å™¨
        temp_retriever = ToolRetriever(instruction_corpus, instruction_to_tool_map, all_tools_definitions, k1=k1, b=b)
        recalls_at_1 = []
        
        for _, row in data_df.iterrows():
            # ã€æ³¨æ„ã€‘æˆ‘ä»¬ä½¿ç”¨ 'æŒ‡ä»¤' åˆ—æ¥è¯„æµ‹å¬å›æ•ˆæœï¼Œå› ä¸ºå®ƒä¸è¯­æ–™åº“çš„æ„å»ºæ–¹å¼ä¸€è‡´
            query = row['planï¼ˆåœ¨xxä¸­åšä»€ä¹ˆï¼‰']
            gt = row['ground_truth_tool']
            retrieved, _ = temp_retriever.retrieve_with_scores(query, top_k=1)
            recalls_at_1.append(calculate_recall_at_k(retrieved, gt, k=1))
        
        current_score = np.mean(recalls_at_1)
        if current_score > best_score:
            best_score = current_score
            best_params = {'k1': k1, 'b': b}

    print(f"å‚æ•°æœç´¢å®Œæˆï¼æœ€ä½³å‚æ•°: {best_params} (åœ¨å®Œæ•´æ•°æ®é›†ä¸Šçš„ Recall@1: {best_score:.4f})\n")

    # --- 3. æ„å»ºæœ€ç»ˆå¬å›å™¨ ---
    print("--- æ­¥éª¤ 3: ä½¿ç”¨æœ€ä½³å‚æ•°å’Œå®Œæ•´æ•°æ®æ„å»ºæœ€ç»ˆå¬å›å™¨ ---")
    # ã€ä¿®æ”¹ç‚¹ã€‘ä½¿ç”¨æ–°çš„æ–¹å¼å’Œæœ€ä½³å‚æ•°æ„å»ºæœ€ç»ˆå¬å›å™¨
    retriever = ToolRetriever(instruction_corpus, instruction_to_tool_map, all_tools_definitions, k1=best_params['k1'], b=best_params['b'])
    print("æœ€ç»ˆå¬å›å™¨æ„å»ºå®Œæˆã€‚\n")

    # --- 4. åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè¯„æµ‹ ---
    print(f"--- æ­¥éª¤ 4: å¼€å§‹åœ¨ {len(data_df)} æ¡æ ·æœ¬ä¸Šè¿›è¡Œè¯„æµ‹ ---")
    results = {
        'Recall@K': {k: [] for k in K_VALUES}, 'HR@K': {k: [] for k in K_VALUES},
        'MAP@K': {k: [] for k in K_VALUES}, 'MRR@K': {k: [] for k in K_VALUES},
        'NDCG@K': {k: [] for k in K_VALUES}, 'COMP@K': {k: [] for k in K_VALUES},
        'AUC': [], 'processing_time': []
    }
    error_cases = []

    for i, (_, row) in enumerate(tqdm(data_df.iterrows(), total=len(data_df), desc="è¯„æµ‹ä¸­")):
        # ã€æ³¨æ„ã€‘è¯„æµ‹æ—¶ï¼Œ query å¯ä»¥æ˜¯ 'plan' æˆ– 'æŒ‡ä»¤'ï¼Œå–å†³äºä½ æƒ³æ¨¡æ‹Ÿçš„çœŸå®åœºæ™¯
        # è¿™é‡Œæˆ‘ä»¬ç»§ç»­ä½¿ç”¨ 'æŒ‡ä»¤' ä½œä¸ºæŸ¥è¯¢ï¼Œä»¥ä¿æŒå’Œå‚æ•°æœç´¢æ—¶çš„ä¸€è‡´æ€§
        query = row['planï¼ˆåœ¨xxä¸­åšä»€ä¹ˆï¼‰'] 
        ground_truth = row['ground_truth_tool']
        
        start_time = time.perf_counter()
        retrieved, all_scores = retriever.retrieve_with_scores(query, top_k=max(K_VALUES))
        duration = time.perf_counter() - start_time
        
        results['processing_time'].append(duration)
        # AUCè¯„æµ‹å‡½æ•°ç°åœ¨å¯ä»¥æ­£ç¡®å·¥ä½œï¼Œå› ä¸ºå®ƒæ¥æ”¶çš„æ˜¯èšåˆåçš„ã€é’ˆå¯¹æ¯ä¸ªå·¥å…·çš„åˆ†æ•°
        results['AUC'].append(calculate_auc_for_query(all_scores, all_tools_definitions, ground_truth))

        for k in K_VALUES:
            results['Recall@K'][k].append(calculate_recall_at_k(retrieved, ground_truth, k))
            results['HR@K'][k].append(calculate_hit_ratio_at_k(retrieved, ground_truth, k))
            results['MAP@K'][k].append(calculate_average_precision_at_k(retrieved, ground_truth, k))
            results['MRR@K'][k].append(calculate_mrr_at_k(retrieved, ground_truth, k))
            results['NDCG@K'][k].append(calculate_ndcg_at_k(retrieved, ground_truth, k))
            results['COMP@K'][k].append(calculate_completeness_at_k(retrieved, ground_truth, k))
        
        is_top1_correct = calculate_recall_at_k(retrieved, ground_truth, k=1) >= 1.0
        if not is_top1_correct:
            gt_name = _get_tool_names(ground_truth).pop() if ground_truth else "N/A"
            pred_name_top1 = retrieved[0].get('name') if retrieved else "N/A"
            error_cases.append({
                "Query": query,
                "Ground Truth": [gt_name],
                "Prediction@1": [pred_name_top1],
                "Prediction@5": [r.get('name') for r in retrieved[:5]]
            })

    # --- 5. æ±‡æ€»å¹¶æŠ¥å‘Šç»“æœ ---
    print("\n\n--- æ­¥éª¤ 5: è¯„æµ‹ç»“æœæŠ¥å‘Š (æ–°é€»è¾‘) ---")
    final_scores = {}
    for metric, vals in results.items():
        if metric == 'AUC': final_scores['AUC'] = np.mean(vals)
        elif metric == 'processing_time': continue
        else: final_scores[metric] = {f"@{k}": np.mean(v) for k, v in vals.items()}
    report_df = pd.DataFrame({ m: final_scores[m] for m in ['Recall@K', 'HR@K', 'MAP@K', 'MRR@K', 'NDCG@K', 'COMP@K']}).T
    report_df.columns = [f"@{k}" for k in K_VALUES]
    print("BM25 å¬å›æ¨¡å‹ (åŸºäºæŒ‡ä»¤æœç´¢) åœ¨å®Œæ•´æ•°æ®é›†ä¸Šçš„è¯„æµ‹ç»“æœ:")
    print("-" * 50)
    print(report_df.to_string(formatters={col: '{:.4f}'.format for col in report_df.columns}))
    print(f"\n**AUC (å…¨é‡æ’åº ROC AUC)**: {final_scores['AUC']:.4f}")
    print("-" * 50)
    
    total_time, avg_time_ms = np.sum(results['processing_time']), np.mean(results['processing_time']) * 1000
    qps = len(data_df) / total_time if total_time > 0 else 0
    print("\næ€§èƒ½è¯„æµ‹:")
    print("-" * 50)
    print(f"æ ·æœ¬æ€»æ•°: {len(data_df)} æ¡")
    print(f"æ€»è€—æ—¶: {total_time:.4f} ç§’, å¹³å‡æ¯æ¡è€—æ—¶: {avg_time_ms:.4f} æ¯«ç§’, QPS: {qps:.2f}")
    print("-" * 50)
    
    # --- 6. æ‰“å°é”™è¯¯åˆ†ææŠ¥å‘Š ---
    print(f"\n\n--- æ­¥éª¤ 6: Top-1 é”™è¯¯æ¡ˆä¾‹åˆ†æ (å…± {len(error_cases)} ä¸ªé”™è¯¯) ---")
    if not error_cases:
        print("ğŸ‰ æ­å–œï¼åœ¨æ•°æ®é›†ä¸Šæ²¡æœ‰å‘ç° Top-1 é”™è¯¯æ¡ˆä¾‹ï¼")
    else:
        for i, case in enumerate(error_cases[:NUM_ERROR_EXAMPLES_TO_PRINT]):
            print(f"\n--- é”™è¯¯æ¡ˆä¾‹ {i+1}/{len(error_cases)} ---")
            print(f"  [æŸ¥è¯¢ Query]: {case['Query']}")
            print(f"  [çœŸå®å·¥å…· Ground Truth]: {case['Ground Truth']}")
            print(f"  [é¢„æµ‹å·¥å…· Prediction@1]: {case['Prediction@1']}")
            print(f"  [é¢„æµ‹å·¥å…· Prediction@5]: {case['Prediction@5']}")
        if len(error_cases) > NUM_ERROR_EXAMPLES_TO_PRINT:
            print(f"\n... (ä»…æ˜¾ç¤ºå‰ {NUM_ERROR_EXAMPLES_TO_PRINT} ä¸ªé”™è¯¯æ¡ˆä¾‹) ...")
    print("-" * 50)


if __name__ == "__main__":
    main()